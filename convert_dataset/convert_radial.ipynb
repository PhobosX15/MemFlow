{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "# move to the root directory\n",
    "#os.chdir(\"../MemFlow/\")\n",
    "from core.Networks import build_network\n",
    "from configs.kitti_memflownet import get_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pavan/SRA/.venv/lib/python3.11/site-packages/torch/__init__.py\n"
     ]
    }
   ],
   "source": [
    "print(torch.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MemFlowNet_skflow\n",
      "[Using basicencoder as context encoder]\n",
      "[Using basicencoder as feature encoder]\n",
      "[Using GMA-SK2]\n",
      "[Using corr_fn default]\n"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg()\n",
    "model = build_network(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kitti_weights = \"/home/pavan/MemFlow/Weights/Memflow weights/MemFlowNet_kitti.pth\"\n",
    "model.load_state_dict(torch.load(kitti_weights)['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cnet.__sizeof__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fnet.__sizeof__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[0.6593, 0.6992],\n",
      "           [0.7205, 0.1069]],\n",
      "\n",
      "          [[0.2074, 0.9261],\n",
      "           [0.9792, 0.0663]]],\n",
      "\n",
      "\n",
      "         [[[0.1914, 0.8234],\n",
      "           [0.0649, 0.3367]],\n",
      "\n",
      "          [[0.7605, 0.2909],\n",
      "           [0.9313, 0.4216]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0.2341, 0.0851],\n",
      "           [0.8776, 0.5528]],\n",
      "\n",
      "          [[0.6996, 0.0929],\n",
      "           [0.5199, 0.4828]]],\n",
      "\n",
      "\n",
      "         [[[0.8608, 0.4582],\n",
      "           [0.4901, 0.6517]],\n",
      "\n",
      "          [[0.0937, 0.0750],\n",
      "           [0.5717, 0.8803]]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.6593, 0.6992],\n",
       "          [0.7205, 0.1069]],\n",
       "\n",
       "         [[0.2074, 0.9261],\n",
       "          [0.9792, 0.0663]]],\n",
       "\n",
       "\n",
       "        [[[0.1914, 0.8234],\n",
       "          [0.0649, 0.3367]],\n",
       "\n",
       "         [[0.7605, 0.2909],\n",
       "          [0.9313, 0.4216]]],\n",
       "\n",
       "\n",
       "        [[[0.2341, 0.0851],\n",
       "          [0.8776, 0.5528]],\n",
       "\n",
       "         [[0.6996, 0.0929],\n",
       "          [0.5199, 0.4828]]],\n",
       "\n",
       "\n",
       "        [[[0.8608, 0.4582],\n",
       "          [0.4901, 0.6517]],\n",
       "\n",
       "         [[0.0937, 0.0750],\n",
       "          [0.5717, 0.8803]]]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random tensor of shape 3x3\n",
    "x = torch.rand(2,2,2,2, 2)\n",
    "print(x)\n",
    "x.flatten(0,1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MemFlowNet(\n",
       "  (cnet): BasicEncoder(\n",
       "    (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (conv2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (fnet): BasicEncoder(\n",
       "    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (conv2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (update_block): SKUpdateBlock6_Deep_nopoolres_AllDecoder2_Mem_skflow(\n",
       "    (encoder): SKMotionEncoder6_Deep_nopool_res_Mem_skflow(\n",
       "      (convc1): PCBlock4_Deep_nopool_res(\n",
       "        (conv_list): ModuleList(\n",
       "          (0): Conv2d(324, 324, kernel_size=(1, 1), stride=(1, 1), groups=324)\n",
       "          (1): Conv2d(324, 324, kernel_size=(15, 15), stride=(1, 1), padding=(7, 7), groups=324)\n",
       "        )\n",
       "        (ffn1): Sequential(\n",
       "          (0): Conv2d(324, 486, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(486, 324, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (pw): Conv2d(324, 324, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (ffn2): Sequential(\n",
       "          (0): Conv2d(324, 486, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(486, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (convc2): PCBlock4_Deep_nopool_res(\n",
       "        (conv_list): ModuleList(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), groups=256)\n",
       "          (1): Conv2d(256, 256, kernel_size=(15, 15), stride=(1, 1), padding=(7, 7), groups=256)\n",
       "        )\n",
       "        (ffn1): Sequential(\n",
       "          (0): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (pw): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (ffn2): Sequential(\n",
       "          (0): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (convf1): Conv2d(2, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (convf2): PCBlock4_Deep_nopool_res(\n",
       "        (conv_list): ModuleList(\n",
       "          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), groups=128)\n",
       "          (1): Conv2d(128, 128, kernel_size=(15, 15), stride=(1, 1), padding=(7, 7), groups=128)\n",
       "        )\n",
       "        (ffn1): Sequential(\n",
       "          (0): Conv2d(128, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (pw): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (ffn2): Sequential(\n",
       "          (0): Conv2d(128, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (conv): PCBlock4_Deep_nopool_res(\n",
       "        (conv_list): ModuleList(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), groups=256)\n",
       "          (1): Conv2d(256, 256, kernel_size=(15, 15), stride=(1, 1), padding=(7, 7), groups=256)\n",
       "        )\n",
       "        (ffn1): Sequential(\n",
       "          (0): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (pw): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (ffn2): Sequential(\n",
       "          (0): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(384, 126, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (gru): PCBlock4_Deep_nopool_res(\n",
       "      (conv_list): ModuleList(\n",
       "        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), groups=512)\n",
       "        (1): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "      )\n",
       "      (ffn1): Sequential(\n",
       "        (0): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (pw): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (ffn2): Sequential(\n",
       "        (0): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (flow_head): PCBlock4_Deep_nopool_res(\n",
       "      (conv_list): ModuleList(\n",
       "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), groups=128)\n",
       "        (1): Conv2d(128, 128, kernel_size=(15, 15), stride=(1, 1), padding=(7, 7), groups=128)\n",
       "      )\n",
       "      (ffn1): Sequential(\n",
       "        (0): Conv2d(128, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (pw): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (ffn2): Sequential(\n",
       "        (0): Conv2d(128, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Conv2d(192, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (mask): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(256, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (aggregator): Aggregate(\n",
       "      (to_v): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (att): Attention(\n",
       "    (to_qk): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (pos_emb): RelPosEmb(\n",
       "      (rel_height): Embedding(319, 128)\n",
       "      (rel_width): Embedding(319, 128)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying with Demo Image from the repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image1 = \"/home/pavan/MemFlow/demo_input_images/frame_0001.png\"\n",
    "input_image2 = \"/home/pavan/MemFlow/demo_input_images/frame_0002.png\"\n",
    "input_image3 = \"/home/pavan/MemFlow/demo_input_images/frame_0003.png\"\n",
    "\n",
    "input_image4 = \"/home/pavan/MemFlow/demo_input_images/frame_0004.png\"\n",
    "input_image5 = \"/home/pavan/MemFlow/demo_input_images/frame_0005.png\"\n",
    "input_image6 = \"/home/pavan/MemFlow/demo_input_images/frame_0006.png\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" img1 = cv2.imread(input_image1)\n",
    "img2 = cv2.imread(input_image2)\n",
    "img3 = cv2.imread(input_image3)\n",
    "\n",
    "img4 = cv2.imread(input_image4)\n",
    "img5 = cv2.imread(input_image5)\n",
    "img6 = cv2.imread(input_image6)\n",
    " \"\"\"\n",
    "\n",
    "# REplace img 1 to 6 with dummy array of shape 224x224x3\n",
    "img1 = np.random.rand(224,224,3)\n",
    "img2 = np.random.rand(224,224,3)\n",
    "img3 = np.random.rand(224,224,3)\n",
    "\n",
    "img4 = np.random.rand(224,224,3)\n",
    "img5 = np.random.rand(224,224,3)\n",
    "img6 = np.random.rand(224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the 3 images as tensors\n",
    "input_frame1 = np.stack([img1, img2, img3], axis=0)\n",
    "input_frame2 = np.stack([img4, img5, img6], axis=0)\n",
    "\n",
    "input_frame1 = torch.tensor(input_frame1).permute(0,3,1,2).float()\n",
    "input_frame2 = torch.tensor(input_frame2).permute(0,3,1,2).float()\n",
    "\n",
    "# stack the 2 frames as tensors\n",
    "input_frames = torch.stack([input_frame1, input_frame2], dim=0)\n",
    "input_frames = input_frames.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords0, coords1, fmaps = model.encode_features(input_frames,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "query, key, net, inp = model.encode_context(input_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 128, 3, 28, 28]),\n",
       " torch.Size([2, 128, 3, 28, 28]),\n",
       " torch.Size([2, 3, 128, 28, 28]),\n",
       " torch.Size([2, 3, 128, 28, 28]))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.shape, key.shape, net.shape, inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "FlashAttention only supports Ampere GPUs or newer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m flow_prediction, current_values \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_flow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoords0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoords1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mfmaps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MemFlow/core/Networks/MemFlowNet/MemFlow.py:147\u001b[0m, in \u001b[0;36mMemFlowNet.predict_flow\u001b[0;34m(self, net, inp, coords0, coords1, fmaps, query, ref_keys, ref_values, test_mode)\u001b[0m\n\u001b[1;32m    145\u001b[0m value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mflatten(start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    146\u001b[0m scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matt\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mlog(ref_keys\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_avg_length)\n\u001b[0;32m--> 147\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mflash_attn_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msoftmax_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcausal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(motion_features\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    150\u001b[0m motion_features_global \u001b[38;5;241m=\u001b[39m motion_features \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_block\u001b[38;5;241m.\u001b[39maggregator\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/SRA/.venv/lib/python3.11/site-packages/flash_attn/flash_attn_interface.py:1201\u001b[0m, in \u001b[0;36mflash_attn_func\u001b[0;34m(q, k, v, dropout_p, softmax_scale, causal, window_size, softcap, alibi_slopes, deterministic, return_attn_probs)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflash_attn_func\u001b[39m(\n\u001b[1;32m   1141\u001b[0m     q,\n\u001b[1;32m   1142\u001b[0m     k,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1151\u001b[0m     return_attn_probs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1152\u001b[0m ):\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"dropout_p should be set to 0.0 during evaluation\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;124;03m    Supports multi-query and grouped-query attention (MQA/GQA) by passing in KV with fewer heads\u001b[39;00m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;124;03m    than Q. Note that the number of heads in Q must be divisible by the number of heads in KV.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1199\u001b[0m \u001b[38;5;124;03m            pattern (negative means that location was dropped, nonnegative means it was kept).\u001b[39;00m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFlashAttnFunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m        \u001b[49m\u001b[43msoftmax_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcausal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m        \u001b[49m\u001b[43msoftcap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m        \u001b[49m\u001b[43malibi_slopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attn_probs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_grad_enabled\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SRA/.venv/lib/python3.11/site-packages/torch/autograd/function.py:598\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    597\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 598\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    602\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    603\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    604\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    605\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    606\u001b[0m     )\n",
      "File \u001b[0;32m~/SRA/.venv/lib/python3.11/site-packages/flash_attn/flash_attn_interface.py:839\u001b[0m, in \u001b[0;36mFlashAttnFunc.forward\u001b[0;34m(ctx, q, k, v, dropout_p, softmax_scale, causal, window_size, softcap, alibi_slopes, deterministic, return_softmax, is_grad_enabled)\u001b[0m\n\u001b[1;32m    837\u001b[0m     k \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mpad(k, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m8\u001b[39m \u001b[38;5;241m-\u001b[39m head_size_og \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m8\u001b[39m])\n\u001b[1;32m    838\u001b[0m     v \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mpad(v, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m8\u001b[39m \u001b[38;5;241m-\u001b[39m head_size_og \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m8\u001b[39m])\n\u001b[0;32m--> 839\u001b[0m out_padded, softmax_lse, S_dmask, rng_state \u001b[38;5;241m=\u001b[39m \u001b[43m_wrapped_flash_attn_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43msoftmax_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcausal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_size_left\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_size_right\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43msoftcap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msoftcap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43malibi_slopes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malibi_slopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_softmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_softmax\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_grad:\n\u001b[1;32m    853\u001b[0m     ctx\u001b[38;5;241m.\u001b[39msave_for_backward(q, k, v, out_padded, softmax_lse, rng_state)\n",
      "File \u001b[0;32m~/SRA/.venv/lib/python3.11/site-packages/flash_attn/flash_attn_interface.py:96\u001b[0m, in \u001b[0;36m_flash_attn_forward\u001b[0;34m(q, k, v, dropout_p, softmax_scale, causal, window_size_left, window_size_right, softcap, alibi_slopes, return_softmax)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;129m@_torch_custom_op_wrapper\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflash_attn::_flash_attn_forward\u001b[39m\u001b[38;5;124m\"\u001b[39m, mutates_args\u001b[38;5;241m=\u001b[39m(), device_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_flash_attn_forward\u001b[39m(\n\u001b[1;32m     83\u001b[0m     q: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m     return_softmax: \u001b[38;5;28mbool\u001b[39m\n\u001b[1;32m     94\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m     95\u001b[0m     q, k, v \u001b[38;5;241m=\u001b[39m [maybe_contiguous(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m (q, k, v)]\n\u001b[0;32m---> 96\u001b[0m     out, softmax_lse, S_dmask, rng_state \u001b[38;5;241m=\u001b[39m \u001b[43mflash_attn_gpu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfwd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43malibi_slopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43msoftmax_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcausal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwindow_size_left\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwindow_size_right\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43msoftcap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_softmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out, softmax_lse, S_dmask, rng_state\n",
      "\u001b[0;31mRuntimeError\u001b[0m: FlashAttention only supports Ampere GPUs or newer."
     ]
    }
   ],
   "source": [
    "flow_prediction, current_values = model.predict_flow(net, inp, coords0, coords1, \n",
    "                                                     fmaps, query, key, ref_values=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
